{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a08bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "  Using cached tensorflow-2.13.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Using cached tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl (276.5 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.10.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (20.9)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (52.0.0.post20210125)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.60.0-cp38-cp38-win_amd64.whl (3.7 MB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.25.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (2.4.7)\n",
      "Installing collected packages: markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.13.1 libclang-16.0.6 markdown-3.5.1 opt-einsum-3.3.0 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cf29c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mSystemError\u001b[0m: <built-in method __contains__ of dict object at 0x000002107BA05B40> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2228a6e9ca76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff677a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cols = [\"bike_count\", \"hour\", \"temp\", \"humidity\", \"wind\", \"visibility\", \"dew_pt_temp\", \"radiation\", \"rain\", \"snow\", \"functional\"]\n",
    "df = pd.read_csv(\"SeoulBikeData.csv\").drop([\"Date\", \"Holiday\", \"Seasons\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98719d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94685497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns = dataset_cols\n",
    "df[\"functional\"] = (df[\"functional\"] == \"Yes\").astype(int)\n",
    "df = df[df[\"hour\"] == 12]\n",
    "df = df.drop([\"hour\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fffda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31039745",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in df.columns[1:]:\n",
    "  plt.scatter(df[label], df[\"bike_count\"])\n",
    "  plt.title(label)\n",
    "  plt.ylabel(\"Bike Count at Noon\")\n",
    "  plt.xlabel(label)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbeeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(df.shape) \n",
    "print('\\n \\n \\n ============================================================================================================== \\n \\n \\n')\n",
    "df.info() \n",
    "print('\\n \\n \\n ============================================================================================================== \\n \\n \\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9142db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"wind\", \"visibility\", \"functional\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692edd61",
   "metadata": {},
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3802cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(dataframe, y_label, x_labels=None):\n",
    "  dataframe = copy.deepcopy(dataframe)\n",
    "  if x_labels is None:\n",
    "    X = dataframe[[c for c in dataframe.columns if c!=y_label]].values\n",
    "  else:\n",
    "    if len(x_labels) == 1:\n",
    "      X = dataframe[x_labels[0]].values.reshape(-1, 1)\n",
    "    else:\n",
    "      X = dataframe[x_labels].values\n",
    "\n",
    "  y = dataframe[y_label].values.reshape(-1, 1)\n",
    "  data = np.hstack((X, y))\n",
    "\n",
    "  return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_train_temp, y_train_temp = get_xy(train, \"bike_count\", x_labels=[\"temp\"])\n",
    "_, X_val_temp, y_val_temp = get_xy(val, \"bike_count\", x_labels=[\"temp\"])\n",
    "_, X_test_temp, y_test_temp = get_xy(test, \"bike_count\", x_labels=[\"temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_reg = LinearRegression()\n",
    "temp_reg.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450976c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_reg.score(X_test_temp, y_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39921ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_temp, y_train_temp, label=\"Data\", color=\"blue\")\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "plt.plot(x, temp_reg.predict(np.array(x).reshape(-1, 1)), label=\"Fit\", color=\"red\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of bikes\")\n",
    "plt.xlabel(\"Temp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834f1ad",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff147ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])\n",
    "_, X_train_all, y_train_all = get_xy(train, \"bike_count\", x_labels=df.columns[1:])\n",
    "_, X_val_all, y_val_all = get_xy(val, \"bike_count\", x_labels=df.columns[1:])\n",
    "_, X_test_all, y_test_all = get_xy(test, \"bike_count\", x_labels=df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reg = LinearRegression()\n",
    "all_reg.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3415bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reg.score(X_test_all, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = all_reg.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c689ca1",
   "metadata": {},
   "source": [
    "# Regression with Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ee36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('MSE')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b197333",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_normalizer = tf.keras.layers.Normalization(input_shape=(1,), axis=None)\n",
    "temp_normalizer.adapt(X_train_temp.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nn_model = tf.keras.Sequential([\n",
    "    temp_normalizer,\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = temp_nn_model.fit(\n",
    "    X_train_temp.reshape(-1), y_train_temp,\n",
    "    verbose=0,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_val_temp, y_val_temp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_temp, y_train_temp, label=\"Data\", color=\"blue\")\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "plt.plot(x, temp_nn_model.predict(np.array(x).reshape(-1, 1)), label=\"Fit\", color=\"red\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of bikes\")\n",
    "plt.xlabel(\"Temp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718c439",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_normalizer = tf.keras.layers.Normalization(input_shape=(1,), axis=None)\n",
    "temp_normalizer.adapt(X_train_temp.reshape(-1))\n",
    "\n",
    "nn_model = tf.keras.Sequential([\n",
    "    temp_normalizer,\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60846b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(\n",
    "    X_train_temp, y_train_temp,\n",
    "    validation_data=(X_val_temp, y_val_temp),\n",
    "    verbose=0, epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c5146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_temp, y_train_temp, label=\"Data\", color=\"blue\")\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "plt.plot(x, nn_model.predict(np.array(x).reshape(-1, 1)), label=\"Fit\", color=\"red\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of bikes\")\n",
    "plt.xlabel(\"Temp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a23268",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_normalizer = tf.keras.layers.Normalization(input_shape=(6,), axis=-1)\n",
    "all_normalizer.adapt(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = tf.keras.Sequential([\n",
    "    all_normalizer,\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825096d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(\n",
    "    X_train_all, y_train_all,\n",
    "    validation_data=(X_val_all, y_val_all),\n",
    "    verbose=0, epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b855a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57caa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the MSE for both linear reg and nn\n",
    "y_pred_lr = all_reg.predict(X_test_all)\n",
    "y_pred_nn = nn_model.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6084906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y_real):\n",
    "  return (np.square(y_pred - y_real)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2761f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(y_pred_lr, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724064d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(y_pred_nn, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(aspect=\"equal\")\n",
    "plt.scatter(y_test_all, y_pred_lr, label=\"Lin Reg Preds\")\n",
    "plt.scatter(y_test_all, y_pred_nn, label=\"NN Preds\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "lims = [0, 1800]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.legend()\n",
    "_ = plt.plot(lims, lims, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3847667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91625e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40074f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f953ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
